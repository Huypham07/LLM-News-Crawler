spring:
  application:
    name: frontier-service
  data:
    mongodb:
      uri: ${SPRING_DATA_MONGODB_URI:mongodb://root:root@localhost:27017/crawlerdb?authSource=admin}
    # Kafka Configuration
  kafka:
    bootstrap-servers: ${SPRING_KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    consumer:
      group-id: frontier-service
      auto-offset-reset: earliest
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        max.poll.records: 100
        fetch.min.bytes: 1024
        fetch.max.wait.ms: 500

    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
      retries: 3
      properties:
        batch.size: 16384
        linger.ms: 5
        buffer.memory: 33554432

# Logging Configuration
logging:
  level:
    com.vdt.crawler.frontier_service: DEBUG
    org.springframework.kafka: INFO
    org.apache.kafka: WARN
    org.springframework.data.mongodb: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/frontier-service.log
  logback:
    rollingpolicy:
      max-file-size: 100MB
      max-history: 30

# Management and Monitoring
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
  metrics:
    export:
      prometheus:
        enabled: true


server:
  port: 8091
  error:
    whitelabel:
      enabled: false

springdoc:
  swagger-ui:
    path: /api/docs

crawler:
  domains:
    - vnexpress.net
    - tuoitre.vn
    - thanhnien.vn
    - dantri.com.vn